{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "Data wrangling or data preparationis considered the most important part of the whole data analysis process. It basically prepares the data and renders it ready for analysis. The purpose of this project was to gather three different data sets and to merge them into one big data set. The data that was used was original Twitter data from Twitter user @dog_rates. \n",
    "\n",
    "As the name @dog_rates says, it rates dogs. \n",
    "\n",
    "## 2. Gathering Data\n",
    "\n",
    "The data was gathered from three different sources:\n",
    "* 1. Enhanced Twitter archive: this data was provided by the udacity instructor\n",
    "* 2. Image Prediction: this data was scraped\n",
    "* 3. Twitter API Call: this data had to be gathered via a Twitter developer account using Twitter's API\n",
    "\n",
    "## 3. Assessing Data\n",
    "\n",
    "Naturally, the data exhibited various Quality and Tidiness problems that had to be solved prior to analysis: \n",
    "\n",
    "#### Quality Issues:\n",
    "\n",
    "* drop unnecessary columns from archive table such as the various id columns\n",
    "* retweeted_status_timestamp should be datetime as opposed to string\n",
    "* incorrect names or NA in name column \n",
    "* the values for rating_numerator and rating_denominator are occasionally incorrect\n",
    "* missing column for fraction of rating_numertor and denominator \n",
    "* expanded_urls column: tweets/retweets without images\n",
    "* img_num column does not contain any information of value \n",
    "* in all three dataframes the dog breeds are not consistently formatted - sometimes lower or uppercase\n",
    "\n",
    "#### Tidiness Issues:\n",
    "* df1, df2, df3 need to be joined\n",
    "* 4 columns (dogger, floofer, pupper and puppo) for one variable (dog stage) hence could have been included into one column\n",
    "* the column headers of the four dog stages should be saved as categorical\n",
    "\n",
    "## 4. Cleaning Data\n",
    "\n",
    "The quality and tidiness issues had to be cleaned with various methods and functions ranging from the sql-logic of merging datasets based on a primary key to regular expression functions. \n",
    "\n",
    "## 5. Conclusion\n",
    "\n",
    "This project illustrated a very true case of how data needs to be gathered in the real world. It oftentimes comes from different sources and therefore shows different data formatting to name a few. Data Wrangling represents the most arduous part in the entire data analysis lifecycle. However, the better and the more time is spend on cleaning a dataset, the better and more thorough the followed data analysis will be. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
